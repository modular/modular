# MAX cloud configurations

These files correspond to tutorials about how to deploy MAX.

For usage instructions, see the following docs:

- `aws/`, `azure/`, and `gcp`: [Deploy Llama 3 on GPU with MAX
Serve](https://docs.modular.com/max/tutorials/max-serve-local-to-cloud).

- `deploy-aws-kubernetes/` and `helm/`: [Deploy Llama 3 on GPU-powered Kubernetes
clusters](https://docs.modular.com/max/tutorials/deploy-max-serve-on-kubernetes)
